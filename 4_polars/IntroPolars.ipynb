{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQknCGesuK91"
      },
      "source": [
        "# Introducción a Polars 🐻‍❄️\n",
        "\n",
        "> **Descripción:** Cuaderno de contenidos sobre introducción a Polars para el Bootcamp de Ciencia de Datos en Código Facilito, 2023. <br>\n",
        "> **Autor:** [Rodolfo Ferro](https://github.com/RodolfoFerro) <br>\n",
        "> **Contacto:** [Twitter](https://twitter.com/rodo_ferro) / [Instagram](https://www.instagram.com/rodo_ferro/)\n",
        "\n",
        "\n",
        "## Contenido\n",
        "\n",
        "### **Sección I**\n",
        "- ¿Qué es Polars?\n",
        "- Polars vs. Pandas\n",
        "- El crecimiento de Polars\n",
        "\n",
        "### **Sección II**\n",
        "- Tipos y estructuras de datos\n",
        "- Contextos y expresiones\n",
        "- Lazy / Eager API\n",
        "\n",
        "### **Sección III – Ejercicios**\n",
        "- Ejemplos con expresiones y transformaciones\n",
        "- SQL context\n",
        "- Ejercicios de tarea\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNVG2PnSEtQN"
      },
      "source": [
        "## **Sección I**\n",
        "\n",
        "Para más detalles, te recomiendo revisar la presentación que puedes encontrar [aquí](https://rodolfoferro.xyz/polars-facilito/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKK_WJFdurLB"
      },
      "source": [
        "### **¿Qué es Polars?**\n",
        "\n",
        "<center>\n",
        "    <img src=\"https://raw.githubusercontent.com/pola-rs/polars-static/master/logos/polars_github_logo_rect_dark_name.svg\" width=\"70%\">\n",
        "</center>\n",
        "\n",
        "**Polars** es una _**DataFrame** library_ de código abierto y de alto rendimiento para manipular datos estructurados. Su core está escrito en Rust, pero la biblioteca está disponible en Python, Rust y NodeJS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VBY5EtDu2uF"
      },
      "source": [
        "### **Polars vs Pandas**\n",
        "\n",
        "Si bien, **Pandas** es una de las bibliotecas más utilizadas para trabajar con datos, una ventaja de **Polars**, al estar hecho con un lenguaje compilado, es que le permite tener un alto rendimiento para manipular datos estructurados.\n",
        "\n",
        "Hay un benchmark realizado por el equipo de Polars, el cual puedes revisar aquí: https://www.pola.rs/benchmarks.html\n",
        "\n",
        "En el link anterior podrás encontrar gráficos como estos:\n",
        "\n",
        "<center>\n",
        "    <img src=\"https://raw.githubusercontent.com/pola-rs/polars-static/master/benchmarks/tpch/sf_10_and_io.png\" width=\"70%\">\n",
        "    <img src=\"https://raw.githubusercontent.com/pola-rs/polars-static/master/benchmarks/tpch/sf_10.png\" width=\"70%\">\n",
        "</center>\n",
        "\n",
        "Estos gráficos muestran resultados de pruebas de rendimiento al trabajar Polars y en contraste con otras herremientas (en elleas incluido Pandas). Dichos benchmarks son básicamente pruebas de memoria y carga de datos.\n",
        "\n",
        "Puedes obtener más detalles de dicho benchmark en el link ya meniconado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKOUbHduvTzC"
      },
      "source": [
        "## **Sección II**\n",
        "\n",
        "Comenzamos con la instalación de `polars`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m7PxZrxvtzsZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: polars in /Users/alejandrodiazvillagomez/Desktop/Data Science Projects/env/lib/python3.12/site-packages (0.20.17)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install polars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8pg5CFkwdzY"
      },
      "source": [
        "### **Tipos y estructuras de datos**\n",
        "\n",
        "En esta sección, exploraremos en detalle los tipos y estructuras de datos que Polars ofrece como alternativa a Pandas. Una comprensión sólida de estos elementos es esencial para aprovechar al máximo las capacidades de Polars y tomar decisiones informadas sobre cuándo y cómo usar esta librería en lugar de otras opciones como Pandas.\n",
        "\n",
        "Todos los tipos y las estructuras de datos están basadas en `Arrow`, una implementación completa, segura y nativa de Rust de [_Apache Arrow_](https://arrow.apache.org/), que es una plataforma de desarrollo multilenguaje para datos en memoria."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgM2-u0fxD9u"
      },
      "source": [
        "#### Tipos de Datos en Polars\n",
        "\n",
        "\n",
        "\n",
        "Polars introduce una gama de tipos de datos optimizados que permiten un mejor rendimiento y uso eficiente de la memoria en comparación con Pandas. Algunos de los tipos de datos clave en Polars incluyen:\n",
        "\n",
        "- **Integer:** Polars ofrece varios tipos de enteros con diferentes tamaños, como `Int8`, `Int16`, `Int32` y `Int64`. Asimismo, números enteros sin signo, como `UInt8`, `UInt16`, `UInt32` y `UInt64`. Estos tipos permiten un control más preciso sobre la cantidad de memoria utilizada.\n",
        "\n",
        "- **Floating-Point:** Al igual que Pandas, Polars ofrece tipos de punto flotante como `Float32` y `Float64` para manejar números decimales con diferentes niveles de precisión.\n",
        "\n",
        "- **Boolean:** Polars utiliza el tipo `Boolean` para representar valores booleanos (verdadero/falso) de manera eficiente.\n",
        "\n",
        "- **Temporal:** Polars proporciona tipos de datos para manejar fechas y horas, como `Date` y `Datetime`, lo que facilita el trabajo con datos temporales."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgK3qfl_yfkU"
      },
      "source": [
        "#### Estructuras de Datos en Polars\n",
        "\n",
        "Polars introduce dos estructuras de datos principales: `DataFrame` y `Series`, que son equivalentes a las estructuras homónimas en Pandas:\n",
        "\n",
        "- **DataFrame:** El equivalente a un DataFrame en Polars es una estructura tabular que organiza los datos en filas y columnas. Polars ofrece una forma de crear y manipular DataFrames, lo que permite realizar operaciones complejas de manera eficiente.\n",
        "\n",
        "- **Series:** Las Series son equivalentes a columnas en un DataFrame. Pueden contener un solo tipo de dato y se utilizan para realizar operaciones vectorizadas en los datos.\n",
        "\n",
        "> **Nota:** Polars introduce los LazyFrames. Esencialmente, un `LazyFrame` es una forma más eficiente de trabajar con un conjunto de datos que usar DataFrame. Si reemplazas tu DataFrame con LazyFrame en tu código con Polars, puedes obtener un tiempo de ejecución más rápido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fcL8SyQA4dja"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (5,)\n",
            "Series: 'a' [i64]\n",
            "[\n",
            "\t1\n",
            "\t2\n",
            "\t3\n",
            "\t4\n",
            "\t5\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "import polars as pl\n",
        "\n",
        "s = pl.Series(\"a\", [1, 2, 3, 4, 5])\n",
        "print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9Cmy3lnowddo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (5, 3)\n",
            "┌─────────┬─────────────────────┬───────┐\n",
            "│ integer ┆ date                ┆ float │\n",
            "│ ---     ┆ ---                 ┆ ---   │\n",
            "│ i64     ┆ datetime[μs]        ┆ f64   │\n",
            "╞═════════╪═════════════════════╪═══════╡\n",
            "│ 1       ┆ 2022-01-01 00:00:00 ┆ 4.0   │\n",
            "│ 2       ┆ 2022-01-02 00:00:00 ┆ 5.0   │\n",
            "│ 3       ┆ 2022-01-03 00:00:00 ┆ 6.0   │\n",
            "│ 4       ┆ 2022-01-04 00:00:00 ┆ 7.0   │\n",
            "│ 5       ┆ 2022-01-05 00:00:00 ┆ 8.0   │\n",
            "└─────────┴─────────────────────┴───────┘\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "df = pl.DataFrame(\n",
        "    {\n",
        "        \"integer\": [1, 2, 3, 4, 5],\n",
        "        \"date\": [\n",
        "            datetime(2022, 1, 1),\n",
        "            datetime(2022, 1, 2),\n",
        "            datetime(2022, 1, 3),\n",
        "            datetime(2022, 1, 4),\n",
        "            datetime(2022, 1, 5),\n",
        "        ],\n",
        "        \"float\": [4.0, 5.0, 6.0, 7.0, 8.0],\n",
        "    }\n",
        ")\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dzc0hdAV4-sr"
      },
      "source": [
        "### **Contextos y expresiones**\n",
        "\n",
        "Polars ha desarrollado su propio lenguaje específico de dominio (DSL) para transformar datos. El lenguaje es muy fácil de usar y permite consultas complejas que siguen siendo legibles por humanos. Los dos componentes centrales del lenguaje son \"Contextos\" y \"Expresiones\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j3OShyO5GhF"
      },
      "source": [
        "#### Contextos\n",
        "\n",
        "Un contexto, como lo implica el nombre, se refiere al contexto en el que se debe evaluar una expresión. Hay tres contextos principales:\n",
        "\n",
        "- Selección: `df.select([..])`, `df.with_columns([..])`\n",
        "- Filtrado: `df.filter()`\n",
        "- Agrupaciones y agregaciones: `df.groupby(..).agg([..])`\n",
        "\n",
        "Revisemos algunos ejemplos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhUMLd6q6Z-s"
      },
      "source": [
        "Comenzemos creando un nuevo dataframe con algo de información."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FFHD9m495bmb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (5, 4)\n",
            "┌──────┬───────┬──────────┬────────┐\n",
            "│ nid  ┆ names ┆ random   ┆ groups │\n",
            "│ ---  ┆ ---   ┆ ---      ┆ ---    │\n",
            "│ i64  ┆ str   ┆ f64      ┆ str    │\n",
            "╞══════╪═══════╪══════════╪════════╡\n",
            "│ 1    ┆ Rodo  ┆ 0.473269 ┆ A      │\n",
            "│ 2    ┆ Hiram ┆ 0.51131  ┆ A      │\n",
            "│ 3    ┆ Josué ┆ 0.651848 ┆ C      │\n",
            "│ null ┆ David ┆ 0.073362 ┆ B      │\n",
            "│ 5    ┆ null  ┆ 0.08893  ┆ B      │\n",
            "└──────┴───────┴──────────┴────────┘\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Creamos un dataframe para trabajar con él\n",
        "df = pl.DataFrame(\n",
        "    {\n",
        "        \"nid\": [1, 2, 3, None, 5],\n",
        "        \"names\": [\"Rodo\", \"Hiram\", \"Josué\", \"David\", None],\n",
        "        \"random\": np.random.rand(5),\n",
        "        \"groups\": [\"A\", \"A\", \"C\", \"B\", \"B\"],\n",
        "    }\n",
        ")\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGwkN76w60qw"
      },
      "source": [
        "##### Contexto `select`\n",
        "\n",
        "En este contexto, la selección aplica expresiones sobre columnas. Las expresiones en este contexto deben producir series que tengan la misma longitud o una longitud de 1.\n",
        "\n",
        "Una selección puede producir nuevas columnas que son agregaciones, combinaciones de expresiones o literales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aHreLwpx5nzW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (1, 1)\n",
            "┌─────┐\n",
            "│ nid │\n",
            "│ --- │\n",
            "│ i64 │\n",
            "╞═════╡\n",
            "│ 11  │\n",
            "└─────┘\n"
          ]
        }
      ],
      "source": [
        "out = df.select(\n",
        "    pl.sum(\"nid\"),\n",
        "    #pl.col(\"names\").sort(),\n",
        "    #pl.col(\"names\").first().alias(\"first name\"),\n",
        "    #(pl.mean(\"nid\") * 10).alias(\"10xnid\"),\n",
        ")\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZX9oQzVh7OBI"
      },
      "source": [
        "El contexto de selección es muy poderoso y nos permite realizar expresiones arbitrarias independientes (y en paralelo) entre sí.\n",
        "\n",
        "De manera similar a `select`, existe la sentencia `with_columns` que también es una entrada al contexto de selección. La principal diferencia es que `with_columns` conserva las columnas originales y agrega otras nuevas, mientras que `select` elimina las columnas originales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "B6ZS4ASD6-Ks"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (5, 5)\n",
            "┌──────┬───────┬──────────┬────────┬─────────┐\n",
            "│ nid  ┆ names ┆ random   ┆ groups ┆ nid_sum │\n",
            "│ ---  ┆ ---   ┆ ---      ┆ ---    ┆ ---     │\n",
            "│ i64  ┆ str   ┆ f64      ┆ str    ┆ i64     │\n",
            "╞══════╪═══════╪══════════╪════════╪═════════╡\n",
            "│ 1    ┆ Rodo  ┆ 0.631356 ┆ A      ┆ 11      │\n",
            "│ 2    ┆ Hiram ┆ 0.320696 ┆ A      ┆ 11      │\n",
            "│ 3    ┆ Josué ┆ 0.600547 ┆ C      ┆ 11      │\n",
            "│ null ┆ David ┆ 0.958794 ┆ B      ┆ 11      │\n",
            "│ 5    ┆ null  ┆ 0.546794 ┆ B      ┆ 11      │\n",
            "└──────┴───────┴──────────┴────────┴─────────┘\n"
          ]
        }
      ],
      "source": [
        "df = df.with_columns(\n",
        "    pl.sum(\"nid\").alias(\"nid_sum\"),\n",
        "    #pl.col(\"random\").count().alias(\"count\"),\n",
        ")\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ke7EnCCa66De"
      },
      "source": [
        "##### Contexto `filter`\n",
        "\n",
        "En este contexto, se filtra el marco de datos existente en función de la expresión arbitraria que se evalúa como el tipo de datos booleano."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rAmLwda88BTz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (4, 5)\n",
            "┌──────┬───────┬──────────┬────────┬─────────┐\n",
            "│ nid  ┆ names ┆ random   ┆ groups ┆ nid_sum │\n",
            "│ ---  ┆ ---   ┆ ---      ┆ ---    ┆ ---     │\n",
            "│ i64  ┆ str   ┆ f64      ┆ str    ┆ i64     │\n",
            "╞══════╪═══════╪══════════╪════════╪═════════╡\n",
            "│ 1    ┆ Rodo  ┆ 0.631356 ┆ A      ┆ 11      │\n",
            "│ 3    ┆ Josué ┆ 0.600547 ┆ C      ┆ 11      │\n",
            "│ null ┆ David ┆ 0.958794 ┆ B      ┆ 11      │\n",
            "│ 5    ┆ null  ┆ 0.546794 ┆ B      ┆ 11      │\n",
            "└──────┴───────┴──────────┴────────┴─────────┘\n"
          ]
        }
      ],
      "source": [
        "out = df.filter(pl.col(\"random\") > 0.5)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJzJSoUB8Lyz"
      },
      "source": [
        "##### Contexto `groupby` / `aggregation`\n",
        "\n",
        "En este contexto, las expresiones funcionan en grupos, por lo que pueden producir resultados de cualquier longitud (un grupo puede tener muchos miembros)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GA4jxg2T8eKx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (3, 2)\n",
            "┌────────┬─────┐\n",
            "│ groups ┆ nid │\n",
            "│ ---    ┆ --- │\n",
            "│ str    ┆ i64 │\n",
            "╞════════╪═════╡\n",
            "│ B      ┆ 5   │\n",
            "│ A      ┆ 3   │\n",
            "│ C      ┆ 3   │\n",
            "└────────┴─────┘\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/zb/tl73nj3d2933b0zx9fk5tfbm0000gn/T/ipykernel_17774/247713983.py:1: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n",
            "  out = df.groupby(\"groups\").agg(\n"
          ]
        }
      ],
      "source": [
        "out = df.groupby(\"groups\").agg(\n",
        "    pl.sum(\"nid\"),  # Suma los nid por groupos\n",
        "    #pl.col(\"random\").count().alias(\"count\"),  # Cuenta miembros de grupo\n",
        "    # Suma random cuando name != null\n",
        "    #pl.col(\"random\").filter(pl.col(\"names\").is_not_null()).sum().suffix(\"_sum\"),\n",
        "    #pl.col(\"names\").reverse().alias(\"reversed names\"),\n",
        ")\n",
        "print(out)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAO33O5o9vAk"
      },
      "source": [
        "#### Expresiones\n",
        "\n",
        "Polars cuenta con expresiones. Las expresiones son el núcleo de muchas operaciones de ciencia de datos y son el concepto fundamental de Polars para su rendimiento muy rápido.\n",
        "\n",
        "Algunas de estas operaciones importantes en la ciencia de datos son:\n",
        "\n",
        "- tomar una muestra de filas de una columna\n",
        "- multiplicar valores en una columna\n",
        "- extraer una columna de años a partir de fechas\n",
        "- convertir una columna de cadenas a minúsculas\n",
        "- ¡y más!\n",
        "\n",
        "Sin embargo, las expresiones también se utilizan dentro de otras operaciones:\n",
        "\n",
        "- tomar la media de un grupo en una operación `groupby`\n",
        "- calcular el tamaño de los grupos en una operación `groupby`\n",
        "- tomando la suma horizontalmente a través de las columnas\n",
        "\n",
        "Polars realiza estas transformaciones de datos centrales muy rápidamente con:\n",
        "\n",
        "- optimización automática de consultas en cada expresión\n",
        "- paralelización automática de expresiones en muchas columnas\n",
        "\n",
        "**Analicemos.** ¿Qué hace la siguiente sentencia?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0d68GFWm-dDS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".rename_alias([(col(\"random\").sort(asc)) > (0.5)])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/zb/tl73nj3d2933b0zx9fk5tfbm0000gn/T/ipykernel_17774/384838403.py:1: DeprecationWarning: `suffix` is deprecated. It has been moved to `name.suffix`.\n",
            "  out = (pl.col(\"random\").sort() > 0.5).suffix(\"_condition\")\n"
          ]
        }
      ],
      "source": [
        "out = (pl.col(\"random\").sort() > 0.5).suffix(\"_condition\")\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSMeAj0K-9An"
      },
      "source": [
        "Notemos que al ejecutar no obtenemos un resultado, esto es porque es necesario ejecutar estas sentencias dentro de un contexto. **Veamos.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FsOcx4Ee_0Yo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (5, 1)\n",
            "┌──────────────────┐\n",
            "│ random_condition │\n",
            "│ ---              │\n",
            "│ bool             │\n",
            "╞══════════════════╡\n",
            "│ false            │\n",
            "│ true             │\n",
            "│ true             │\n",
            "│ true             │\n",
            "│ true             │\n",
            "└──────────────────┘\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/zb/tl73nj3d2933b0zx9fk5tfbm0000gn/T/ipykernel_17774/169161364.py:1: DeprecationWarning: `suffix` is deprecated. It has been moved to `name.suffix`.\n",
            "  out = df.select((pl.col(\"random\").sort() > 0.5).suffix(\"_condition\"))\n"
          ]
        }
      ],
      "source": [
        "out = df.select((pl.col(\"random\").sort() > 0.5).suffix(\"_condition\"))\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HOf5epFC_C5q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (5, 6)\n",
            "┌──────┬───────┬──────────┬────────┬─────────┬──────────────────┐\n",
            "│ nid  ┆ names ┆ random   ┆ groups ┆ nid_sum ┆ random_condition │\n",
            "│ ---  ┆ ---   ┆ ---      ┆ ---    ┆ ---     ┆ ---              │\n",
            "│ i64  ┆ str   ┆ f64      ┆ str    ┆ i64     ┆ bool             │\n",
            "╞══════╪═══════╪══════════╪════════╪═════════╪══════════════════╡\n",
            "│ 1    ┆ Rodo  ┆ 0.631356 ┆ A      ┆ 11      ┆ false            │\n",
            "│ 2    ┆ Hiram ┆ 0.320696 ┆ A      ┆ 11      ┆ true             │\n",
            "│ 3    ┆ Josué ┆ 0.600547 ┆ C      ┆ 11      ┆ true             │\n",
            "│ null ┆ David ┆ 0.958794 ┆ B      ┆ 11      ┆ true             │\n",
            "│ 5    ┆ null  ┆ 0.546794 ┆ B      ┆ 11      ┆ true             │\n",
            "└──────┴───────┴──────────┴────────┴─────────┴──────────────────┘\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/zb/tl73nj3d2933b0zx9fk5tfbm0000gn/T/ipykernel_17774/3777333523.py:1: DeprecationWarning: `suffix` is deprecated. It has been moved to `name.suffix`.\n",
            "  out = df.with_columns((pl.col(\"random\").sort() > 0.5).suffix(\"_condition\"))\n"
          ]
        }
      ],
      "source": [
        "out = df.with_columns((pl.col(\"random\").sort() > 0.5).suffix(\"_condition\"))\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlhsHRAVAQgo"
      },
      "source": [
        "**Observación:** ¿Por qué si ejecutamos un sort, los datos no están ordenados?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz7UQe0F4pna"
      },
      "source": [
        "### **Operaciones \"Lazy\" y \"Eager\"**\n",
        "\n",
        "Una característica única de Polars es su enfoque en las operaciones \"Lazy\" y \"Eager\". Las operaciones \"Lazy\" permiten construir una secuencia de operaciones en un DataFrame sin ejecutarlas de inmediato. Esto puede ser útil para optimizar el rendimiento y evitar cálculos innecesarios. Por otro lado, las operaciones \"Eager\" ejecutan inmediatamente las operaciones en el DataFrame y devuelven los resultados.\n",
        "\n",
        "**Analicemos.** ¿Qué sucede en el siguiente ejemplo?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mTnbPhzw4wjQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
            "Wall time: 3.81 µs\n",
            "shape: (3, 2)\n",
            "┌────────────┬─────────────┐\n",
            "│ species    ┆ sepal_width │\n",
            "│ ---        ┆ ---         │\n",
            "│ str        ┆ f64         │\n",
            "╞════════════╪═════════════╡\n",
            "│ setosa     ┆ 3.713636    │\n",
            "│ virginica  ┆ 2.983673    │\n",
            "│ versicolor ┆ 2.804255    │\n",
            "└────────────┴─────────────┘\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/zb/tl73nj3d2933b0zx9fk5tfbm0000gn/T/ipykernel_17774/2752805844.py:4: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n",
            "  df_agg = df_small.groupby(\"species\").agg(pl.col(\"sepal_width\").mean())\n"
          ]
        }
      ],
      "source": [
        "%time\n",
        "df = pl.read_csv(\"iris.csv\")\n",
        "df_small = df.filter(pl.col(\"sepal_length\") > 5)\n",
        "df_agg = df_small.groupby(\"species\").agg(pl.col(\"sepal_width\").mean())\n",
        "print(df_agg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMvlXTCIBE0A"
      },
      "source": [
        "En este ejemplo, usamos la API \"Eager\" para:\n",
        "\n",
        "- Leer el conjunto de datos del iris.\n",
        "- Filtrar el conjunto de datos según la longitud del sépalo\n",
        "- Calcular la media del ancho del sépalo por especie\n",
        "\n",
        "Cada paso se ejecuta inmediatamente devolviendo los resultados intermedios. Esto puede ser un fallo a la eficiencia, ya que podríamos trabajar o cargar datos adicionales que no se están utilizando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "smoExF38BoSA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: wget\n"
          ]
        }
      ],
      "source": [
        "# !wget https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lWOrXZoyBBeM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1e+03 ns, sys: 1e+03 ns, total: 2 µs\n",
            "Wall time: 3.81 µs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/zb/tl73nj3d2933b0zx9fk5tfbm0000gn/T/ipykernel_17774/757766384.py:5: DeprecationWarning: `groupby` is deprecated. It has been renamed to `group_by`.\n",
            "  .groupby(\"species\")\n"
          ]
        }
      ],
      "source": [
        "%time\n",
        "q = (\n",
        "    pl.scan_csv(\"iris.csv\")\n",
        "    .filter(pl.col(\"sepal_length\") > 5)\n",
        "    .groupby(\"species\")\n",
        "    .agg(pl.col(\"sepal_width\").mean())\n",
        ")\n",
        "\n",
        "df = q.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pu-fXyS3Br36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (3, 2)\n",
            "┌────────────┬─────────────┐\n",
            "│ species    ┆ sepal_width │\n",
            "│ ---        ┆ ---         │\n",
            "│ str        ┆ f64         │\n",
            "╞════════════╪═════════════╡\n",
            "│ setosa     ┆ 3.713636    │\n",
            "│ virginica  ┆ 2.983673    │\n",
            "│ versicolor ┆ 2.804255    │\n",
            "└────────────┴─────────────┘\n"
          ]
        }
      ],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--NiTEC3CwrU"
      },
      "source": [
        "## **Sección III**\n",
        "\n",
        "Estaremos poniendo en práctica lo aprendido con algunos ejercicios de [101 Pandas Exercises for Data Analysis](https://www.machinelearningplus.com/python/101-pandas-exercises-python/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNcBnJ1kC8UW"
      },
      "source": [
        "### **Ejemplos con expresiones y transformaciones**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcQ6tv6xPDot"
      },
      "source": [
        "#### 4. ¿Cómo combinar múltiples dfs en un DataFrame?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "il7rfC2lC-SO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (26, 1)\n",
            "┌────────┐\n",
            "│ letras │\n",
            "│ ---    │\n",
            "│ str    │\n",
            "╞════════╡\n",
            "│ a      │\n",
            "│ b      │\n",
            "│ c      │\n",
            "│ e      │\n",
            "│ d      │\n",
            "│ …      │\n",
            "│ v      │\n",
            "│ w      │\n",
            "│ x      │\n",
            "│ y      │\n",
            "│ z      │\n",
            "└────────┘ shape: (26, 1)\n",
            "┌──────┐\n",
            "│ nums │\n",
            "│ ---  │\n",
            "│ i64  │\n",
            "╞══════╡\n",
            "│ 0    │\n",
            "│ 1    │\n",
            "│ 2    │\n",
            "│ 3    │\n",
            "│ 4    │\n",
            "│ …    │\n",
            "│ 21   │\n",
            "│ 22   │\n",
            "│ 23   │\n",
            "│ 24   │\n",
            "│ 25   │\n",
            "└──────┘\n"
          ]
        }
      ],
      "source": [
        "# 4. ¿Cómo combinar múltiples dfs en un DataFrame?\n",
        "df1 = pl.DataFrame({\"letras\": list(\"abcedfghijklmnopqrstuvwxyz\")})\n",
        "df2 = pl.DataFrame({\"nums\": np.arange(len(df1))})\n",
        "\n",
        "print(df1, df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9QpTxpkZGDbx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (26, 2)\n",
            "┌────────┬──────┐\n",
            "│ letras ┆ nums │\n",
            "│ ---    ┆ ---  │\n",
            "│ str    ┆ i64  │\n",
            "╞════════╪══════╡\n",
            "│ a      ┆ 0    │\n",
            "│ b      ┆ 1    │\n",
            "│ c      ┆ 2    │\n",
            "│ e      ┆ 3    │\n",
            "│ d      ┆ 4    │\n",
            "│ …      ┆ …    │\n",
            "│ v      ┆ 21   │\n",
            "│ w      ┆ 22   │\n",
            "│ x      ┆ 23   │\n",
            "│ y      ┆ 24   │\n",
            "│ z      ┆ 25   │\n",
            "└────────┴──────┘\n"
          ]
        }
      ],
      "source": [
        "### Solución\n",
        "df3 = pl.concat([df1, df2], how=\"horizontal\")\n",
        "print(df3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAuCiAKBPqah"
      },
      "source": [
        "#### 14. ¿Cómo extraer items de un DataFrame dadas las posiciones a través de enteros?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_61CU5qDP2Bs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (26, 1)\n",
            "┌──────────┐\n",
            "│ column_0 │\n",
            "│ ---      │\n",
            "│ str      │\n",
            "╞══════════╡\n",
            "│ a        │\n",
            "│ b        │\n",
            "│ c        │\n",
            "│ d        │\n",
            "│ e        │\n",
            "│ …        │\n",
            "│ v        │\n",
            "│ w        │\n",
            "│ x        │\n",
            "│ y        │\n",
            "│ z        │\n",
            "└──────────┘\n"
          ]
        }
      ],
      "source": [
        "# 14. ¿Cómo extraer items de un DataFrame dadas las posiciones a través de enteros?\n",
        "df = pl.DataFrame(list('abcdefghijklmnopqrstuvwxyz'))\n",
        "pos = [0, 4, 8, 14, 20]\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "d7BjnoRUP_48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (5, 1)\n",
            "┌──────────┐\n",
            "│ column_0 │\n",
            "│ ---      │\n",
            "│ str      │\n",
            "╞══════════╡\n",
            "│ a        │\n",
            "│ e        │\n",
            "│ i        │\n",
            "│ o        │\n",
            "│ u        │\n",
            "└──────────┘\n"
          ]
        }
      ],
      "source": [
        "### Solución\n",
        "print(df[pos])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLHfSqbdPGOJ"
      },
      "source": [
        "#### 19. ¿Cómo calcular el número de caracteres de cada palabra en un DataFrame?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DtY52y06EXHQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (4, 1)\n",
            "┌──────────┐\n",
            "│ palabras │\n",
            "│ ---      │\n",
            "│ str      │\n",
            "╞══════════╡\n",
            "│ esta     │\n",
            "│ es       │\n",
            "│ una      │\n",
            "│ palabra  │\n",
            "└──────────┘\n"
          ]
        }
      ],
      "source": [
        "# 19. ¿Cómo calcular el número de caracteres de cada palabra en un DataFrame?\n",
        "df = pl.DataFrame({\"palabras\": [\"esta\", \"es\", \"una\", \"palabra\"]})\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "pX9uPtnfGtXF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (4, 2)\n",
            "┌──────────┬──────────┐\n",
            "│ palabras ┆ longitud │\n",
            "│ ---      ┆ ---      │\n",
            "│ str      ┆ u32      │\n",
            "╞══════════╪══════════╡\n",
            "│ esta     ┆ 4        │\n",
            "│ es       ┆ 2        │\n",
            "│ una      ┆ 3        │\n",
            "│ palabra  ┆ 7        │\n",
            "└──────────┴──────────┘\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/zb/tl73nj3d2933b0zx9fk5tfbm0000gn/T/ipykernel_1020/3493192398.py:5: DeprecationWarning: `lengths` is deprecated. It has been renamed to `len_bytes`.\n",
            "  pl.col(\"palabras\").str.lengths().alias(\"longitud\")\n"
          ]
        }
      ],
      "source": [
        "### Solución\n",
        "# print(df.shape[0])\n",
        "\n",
        "out = df.with_columns(\n",
        "    pl.col(\"palabras\").str.lengths().alias(\"longitud\")\n",
        ")\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OesttF2ReGl"
      },
      "source": [
        "#### 23. ¿Cómo convertir una cadena año-mes a fechas que comiencen en el 11 de cada mes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "aYeBcJP1Ro0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (3, 1)\n",
            "┌──────────┐\n",
            "│ fechas   │\n",
            "│ ---      │\n",
            "│ str      │\n",
            "╞══════════╡\n",
            "│ Jan 2010 │\n",
            "│ Feb 2011 │\n",
            "│ Mar 2012 │\n",
            "└──────────┘\n"
          ]
        }
      ],
      "source": [
        "# 23. ¿Cómo convertir una cadena año-mes a fechas que comiencen en el 11 de cada mes?\n",
        "df = pl.DataFrame({\"fechas\": ['Jan 2010', 'Feb 2011', 'Mar 2012']})\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MxI5e49QRyFY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (3, 1)\n",
            "┌─────────────────────┐\n",
            "│ fechas_parse        │\n",
            "│ ---                 │\n",
            "│ datetime[μs]        │\n",
            "╞═════════════════════╡\n",
            "│ 2010-01-11 00:00:00 │\n",
            "│ 2011-02-11 00:00:00 │\n",
            "│ 2012-03-11 00:00:00 │\n",
            "└─────────────────────┘\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/zb/tl73nj3d2933b0zx9fk5tfbm0000gn/T/ipykernel_1020/1897838111.py:5: DeprecationWarning: `apply` is deprecated. It has been renamed to `map_elements`.\n",
            "  pl.col(\"fechas\").apply(lambda x: parse(\"11 \" + x)).alias(\"fechas_parse\")\n",
            "/var/folders/zb/tl73nj3d2933b0zx9fk5tfbm0000gn/T/ipykernel_1020/1897838111.py:4: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "  out = df.select(\n"
          ]
        }
      ],
      "source": [
        "### Solución\n",
        "from dateutil.parser import parse\n",
        "\n",
        "out = df.select(\n",
        "    pl.col(\"fechas\").apply(lambda x: parse(\"11 \" + x)).alias(\"fechas_parse\")\n",
        ")\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ekm_Y4IbPJ88"
      },
      "source": [
        "#### 40. ¿Cómo revisar si un DataFrame tiene valores faltantes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "0yLzlOn3JYCb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (5, 27)\n",
            "┌────────────────┬─────────┬─────────┬───────────┬───┬───────────────┬────────┬─────────┬──────────┐\n",
            "│ Manufacturer   ┆ Model   ┆ Type    ┆ Min.Price ┆ … ┆ Luggage.room  ┆ Weight ┆ Origin  ┆ Make     │\n",
            "│ ---            ┆ ---     ┆ ---     ┆ ---       ┆   ┆ ---           ┆ ---    ┆ ---     ┆ ---      │\n",
            "│ str            ┆ str     ┆ str     ┆ str       ┆   ┆ str           ┆ str    ┆ str     ┆ str      │\n",
            "╞════════════════╪═════════╪═════════╪═══════════╪═══╪═══════════════╪════════╪═════════╪══════════╡\n",
            "│ Acura          ┆ Integra ┆ Small   ┆ 12.9      ┆ … ┆ NA            ┆ 2705   ┆ non-USA ┆ Acura    │\n",
            "│                ┆         ┆         ┆           ┆   ┆               ┆        ┆         ┆ Integra  │\n",
            "│ NA             ┆ Legend  ┆ Midsize ┆ 29.2      ┆ … ┆ 15            ┆ 3560   ┆ non-USA ┆ Acura    │\n",
            "│                ┆         ┆         ┆           ┆   ┆               ┆        ┆         ┆ Legend   │\n",
            "│ Audi           ┆ 90      ┆ Compact ┆ 25.9      ┆ … ┆ 14            ┆ 3375   ┆ non-USA ┆ Audi 90  │\n",
            "│ Audi           ┆ 100     ┆ Midsize ┆ NA        ┆ … ┆ 17            ┆ 3405   ┆ non-USA ┆ Audi 100 │\n",
            "│ BMW            ┆ 535i    ┆ Midsize ┆ NA        ┆ … ┆ 13            ┆ 3640   ┆ non-USA ┆ BMW 535i │\n",
            "└────────────────┴─────────┴─────────┴───────────┴───┴───────────────┴────────┴─────────┴──────────┘\n"
          ]
        }
      ],
      "source": [
        "# 40. ¿Cómo revisar si un DataFrame tiene valores faltantes?\n",
        "df = pl.read_csv(\"Cars93_miss.csv\")\n",
        "print(df.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "1FkZZsE-KaZf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (1, 27)\n",
            "┌──────────────┬───────┬──────┬───────────┬───┬──────────────┬────────┬────────┬──────┐\n",
            "│ Manufacturer ┆ Model ┆ Type ┆ Min.Price ┆ … ┆ Luggage.room ┆ Weight ┆ Origin ┆ Make │\n",
            "│ ---          ┆ ---   ┆ ---  ┆ ---       ┆   ┆ ---          ┆ ---    ┆ ---    ┆ ---  │\n",
            "│ u32          ┆ u32   ┆ u32  ┆ u32       ┆   ┆ u32          ┆ u32    ┆ u32    ┆ u32  │\n",
            "╞══════════════╪═══════╪══════╪═══════════╪═══╪══════════════╪════════╪════════╪══════╡\n",
            "│ 4            ┆ 1     ┆ 3    ┆ 7         ┆ … ┆ 19           ┆ 7      ┆ 5      ┆ 3    │\n",
            "└──────────────┴───────┴──────┴───────────┴───┴──────────────┴────────┴────────┴──────┘\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/zb/tl73nj3d2933b0zx9fk5tfbm0000gn/T/ipykernel_1020/863456074.py:5: DeprecationWarning: `apply` is deprecated. It has been renamed to `map_elements`.\n",
            "  pl.all().apply(lambda x: None if x == \"NA\" else x)\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
            "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n"
          ]
        }
      ],
      "source": [
        "### Solución\n",
        "# df.columns = all()\n",
        "\n",
        "out = df.select(\n",
        "    pl.all().apply(lambda x: None if x == \"NA\" else x)\n",
        ")\n",
        "print(out.null_count())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Cc2BDuFPLsc"
      },
      "source": [
        "#### 49. ¿Cómo filtrar cada n-ésima fila en un DataFrame?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "EB5eludRN8-a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (8, 27)\n",
            "┌─────────────┬────────────┬─────────┬───────────┬───┬─────────────┬────────┬─────────┬────────────┐\n",
            "│ Manufacture ┆ Model      ┆ Type    ┆ Min.Price ┆ … ┆ Luggage.roo ┆ Weight ┆ Origin  ┆ Make       │\n",
            "│ r           ┆ ---        ┆ ---     ┆ ---       ┆   ┆ m           ┆ ---    ┆ ---     ┆ ---        │\n",
            "│ ---         ┆ str        ┆ str     ┆ str       ┆   ┆ ---         ┆ str    ┆ str     ┆ str        │\n",
            "│ str         ┆            ┆         ┆           ┆   ┆ str         ┆        ┆         ┆            │\n",
            "╞═════════════╪════════════╪═════════╪═══════════╪═══╪═════════════╪════════╪═════════╪════════════╡\n",
            "│ Acura       ┆ Integra    ┆ Small   ┆ 12.9      ┆ … ┆ NA          ┆ 2705   ┆ non-USA ┆ Acura      │\n",
            "│             ┆            ┆         ┆           ┆   ┆             ┆        ┆         ┆ Integra    │\n",
            "│ NA          ┆ Legend     ┆ Midsize ┆ 29.2      ┆ … ┆ 15          ┆ 3560   ┆ non-USA ┆ Acura      │\n",
            "│             ┆            ┆         ┆           ┆   ┆             ┆        ┆         ┆ Legend     │\n",
            "│ Audi        ┆ 90         ┆ Compact ┆ 25.9      ┆ … ┆ 14          ┆ 3375   ┆ non-USA ┆ Audi 90    │\n",
            "│ Audi        ┆ 100        ┆ Midsize ┆ NA        ┆ … ┆ 17          ┆ 3405   ┆ non-USA ┆ Audi 100   │\n",
            "│ BMW         ┆ 535i       ┆ Midsize ┆ NA        ┆ … ┆ 13          ┆ 3640   ┆ non-USA ┆ BMW 535i   │\n",
            "│ Buick       ┆ Century    ┆ Midsize ┆ 14.2      ┆ … ┆ 16          ┆ NA     ┆ USA     ┆ Buick      │\n",
            "│             ┆            ┆         ┆           ┆   ┆             ┆        ┆         ┆ Century    │\n",
            "│ Buick       ┆ LeSabre    ┆ Large   ┆ 19.9      ┆ … ┆ 17          ┆ 3470   ┆ USA     ┆ Buick      │\n",
            "│             ┆            ┆         ┆           ┆   ┆             ┆        ┆         ┆ LeSabre    │\n",
            "│ Buick       ┆ Roadmaster ┆ Large   ┆ 22.6      ┆ … ┆ 21          ┆ 4105   ┆ USA     ┆ Buick      │\n",
            "│             ┆            ┆         ┆           ┆   ┆             ┆        ┆         ┆ Roadmaster │\n",
            "└─────────────┴────────────┴─────────┴───────────┴───┴─────────────┴────────┴─────────┴────────────┘\n"
          ]
        }
      ],
      "source": [
        "# 49. ¿Cómo filtrar cada n-ésima fila en un DataFrame?\n",
        "df = pl.read_csv(\"Cars93_miss.csv\")\n",
        "print(df.head(8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "VGG2FyD8OFzz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (31, 27)\n",
            "┌──────────────┬─────────┬─────────┬───────────┬───┬──────────────┬────────┬─────────┬─────────────┐\n",
            "│ Manufacturer ┆ Model   ┆ Type    ┆ Min.Price ┆ … ┆ Luggage.room ┆ Weight ┆ Origin  ┆ Make        │\n",
            "│ ---          ┆ ---     ┆ ---     ┆ ---       ┆   ┆ ---          ┆ ---    ┆ ---     ┆ ---         │\n",
            "│ str          ┆ str     ┆ str     ┆ str       ┆   ┆ str          ┆ str    ┆ str     ┆ str         │\n",
            "╞══════════════╪═════════╪═════════╪═══════════╪═══╪══════════════╪════════╪═════════╪═════════════╡\n",
            "│ Acura        ┆ Integra ┆ Small   ┆ 12.9      ┆ … ┆ NA           ┆ 2705   ┆ non-USA ┆ Acura       │\n",
            "│              ┆         ┆         ┆           ┆   ┆              ┆        ┆         ┆ Integra     │\n",
            "│ Audi         ┆ 100     ┆ Midsize ┆ NA        ┆ … ┆ 17           ┆ 3405   ┆ non-USA ┆ Audi 100    │\n",
            "│ Buick        ┆ LeSabre ┆ Large   ┆ 19.9      ┆ … ┆ 17           ┆ 3470   ┆ USA     ┆ Buick       │\n",
            "│              ┆         ┆         ┆           ┆   ┆              ┆        ┆         ┆ LeSabre     │\n",
            "│ Cadillac     ┆ DeVille ┆ Large   ┆ 33        ┆ … ┆ 18           ┆ 3620   ┆ USA     ┆ Cadillac    │\n",
            "│              ┆         ┆         ┆           ┆   ┆              ┆        ┆         ┆ DeVille     │\n",
            "│ Chevrolet    ┆ Corsica ┆ Compact ┆ 11.4      ┆ … ┆ NA           ┆ 2785   ┆ USA     ┆ Chevrolet   │\n",
            "│              ┆         ┆         ┆           ┆   ┆              ┆        ┆         ┆ Corsica     │\n",
            "│ …            ┆ …       ┆ …       ┆ …         ┆ … ┆ …            ┆ …      ┆ …       ┆ …           │\n",
            "│ Saturn       ┆ SL      ┆ Small   ┆ 9.2       ┆ … ┆ NA           ┆ 2495   ┆ USA     ┆ Saturn SL   │\n",
            "│ Subaru       ┆ Legacy  ┆ Compact ┆ 16.3      ┆ … ┆ 14           ┆ 3085   ┆ non-USA ┆ Subaru      │\n",
            "│              ┆         ┆         ┆           ┆   ┆              ┆        ┆         ┆ Legacy      │\n",
            "│ Toyota       ┆ Celica  ┆ Sporty  ┆ 14.2      ┆ … ┆ 13           ┆ 2950   ┆ non-USA ┆ Toyota      │\n",
            "│              ┆         ┆         ┆           ┆   ┆              ┆        ┆         ┆ Celica      │\n",
            "│ Volkswagen   ┆ Fox     ┆ Small   ┆ 8.7       ┆ … ┆ 10           ┆ 2240   ┆ non-USA ┆ Volkswagen  │\n",
            "│              ┆         ┆         ┆           ┆   ┆              ┆        ┆         ┆ Fox         │\n",
            "│ Volkswagen   ┆ Corrado ┆ Sporty  ┆ 22.9      ┆ … ┆ 15           ┆ 2810   ┆ non-USA ┆ Volkswagen  │\n",
            "│              ┆         ┆         ┆           ┆   ┆              ┆        ┆         ┆ Corrado     │\n",
            "└──────────────┴─────────┴─────────┴───────────┴───┴──────────────┴────────┴─────────┴─────────────┘\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/zb/tl73nj3d2933b0zx9fk5tfbm0000gn/T/ipykernel_1020/4041612063.py:4: DeprecationWarning: `take_every` is deprecated. It has been renamed to `gather_every`.\n",
            "  out = df.take_every(3)\n"
          ]
        }
      ],
      "source": [
        "### Solución\n",
        "# print(df[list(range(0, len(df), 3))])\n",
        "\n",
        "out = df.take_every(3)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWBwC4prSgs9"
      },
      "source": [
        "### **SQL context**\n",
        "\n",
        "Aunque Polars admite la escritura de consultas en SQL, se recomienda que las y los usuarios se familiaricen con la sintaxis nativa para obtener un código más legible y expresivo.\n",
        "\n",
        "Sin embargo, si ya cuentas con una base de código SQL existente o prefieres usar SQL, Polars también te ofrece soporte para consultas SQL.\n",
        "\n",
        "Polars utiliza el `SQLContext` para administrar consultas SQL. El contexto contiene un diccionario que asigna nombres de DataFrames y LazyFrames a sus correspondientes conjuntos de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwQu8WbpTIXY"
      },
      "outputs": [],
      "source": [
        "# For local files use scan_csv instead\n",
        "pokemon = pl.read_csv(\n",
        "    \"https://gist.githubusercontent.com/ritchie46/cac6b337ea52281aa23c049250a4ff03/raw/89a957ff3919d90e6ef2d34235e6bf22304f3366/pokemon.csv\"\n",
        ")\n",
        "\n",
        "ctx = pl.SQLContext(register_globals=True, eager_execution=True)\n",
        "df_small = ctx.execute(\"SELECT * from pokemon LIMIT 5\")\n",
        "print(df_small)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKp_PZ_NDqbS"
      },
      "source": [
        "> **Para resolver la tarea, el reto es:** Poner en práctica los conocimientos adquiridos a través de ejercicios y retos.\n",
        "\n",
        "**Puedes explorar:**\n",
        "- [Polars API Reference](https://pola-rs.github.io/polars/py-polars/html/reference/index.html)\n",
        "- [101 Pandas Exercises for Data Analysis](https://www.machinelearningplus.com/python/101-pandas-exercises-python/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSdbQU3e6-Ky"
      },
      "source": [
        "--------\n",
        "\n",
        "> Contenido creado por **Rodolfo Ferro**, 2023. <br>\n",
        "> Puedes contactarme a través de Insta ([@rodo_ferro](https://www.instagram.com/rodo_ferro/)) o Twitter ([@rodo_ferro](https://twitter.com/rodo_ferro))."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
